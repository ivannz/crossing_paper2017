{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Monte Carlo experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A handy routines to store and recover python objects, in particular, the experiment resutls dictionaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time, gzip\n",
    "import os, cPickle\n",
    "\n",
    "def save(obj, path, prefix=None):\n",
    "    prefix_ = \"\" if prefix is None else \"%s_\"%(prefix,)\n",
    "    filename_ = os.path.join(path, \"%s%s.gz\"%(prefix_, time.strftime(\"%Y%m%d-%H%M%S\"),))\n",
    "    with gzip.open(filename_, \"wb+\", 9) as fout_:\n",
    "        cPickle.dump(obj, fout_)\n",
    "    return filename_\n",
    "\n",
    "def load(filename):\n",
    "    with gzip.open(filename, \"rb\") as f:\n",
    "        return cPickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree import structural_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect a list of results returned by path_analyze into aligned data tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree import collect_structural_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function implementing various delta choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def get_delta_method(delta=1.0):\n",
    "    if isinstance(delta, str):\n",
    "        if delta == \"std\":\n",
    "            # the standard deviation of increments\n",
    "            delta_ = lambda X: np.diff(X).std()\n",
    "        elif delta == \"med\":\n",
    "            # Use the median absolute difference [Jones, Rolls; 2009] p. 11 (arxiv:0911.5204v2)\n",
    "            delta_ = lambda X: np.median(np.abs(np.diff(X)))\n",
    "        elif delta == \"iqr\":\n",
    "            # Interquartile range\n",
    "            delta_ = lambda X: np.subtract(*np.percentile(np.diff(X), [75, 25]))\n",
    "        elif delta == \"rng\":\n",
    "            # Use the range estimate as suggested by Geoffrey on 2015-05-28\n",
    "            warnings.warn(\"\"\"Use of `range`-based grid resolution \"\"\"\n",
    "                          \"\"\"is discouraged since it may cause misaligned \"\"\"\n",
    "                          \"\"\"crossing trees.\"\"\", RuntimeWarning)\n",
    "            delta_ = lambda X: (X.max() - X.min()) / (2**12)\n",
    "        else:\n",
    "            raise ValueError(\"\"\"Invalid `delta` setting. Accepted values \"\"\"\n",
    "                             \"\"\"are: [`iqr`, `std`, `med`, `rng`].\"\"\")\n",
    "    elif isinstance(delta, float) and delta > 0:\n",
    "        delta_ = lambda X: delta\n",
    "    else:\n",
    "        raise TypeError(\"\"\"`delta` must be either a float, or a method \"\"\"\n",
    "                        \"\"\"identifier.\"\"\")\n",
    "    return delta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An MC experiment kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def experiment(experiment_id, n_replications, methods, generator):\n",
    "    generator = clone(generator)\n",
    "    generator.start()\n",
    "\n",
    "    deltas = [get_delta_method(method_) for method_ in methods]\n",
    "\n",
    "    results = {method_: list() for method_ in methods}\n",
    "    for j in xrange(n_replications):\n",
    "        T, X = generator.draw()\n",
    "\n",
    "        # Apply all methods to the same sample path.\n",
    "        for delta, method in zip(deltas, methods):\n",
    "            result_ = structural_statistics(X, T, scale=delta(X), origin=X[0])\n",
    "            results[method].append(result_)\n",
    "\n",
    "    generator.finish()\n",
    "\n",
    "    return experiment_id, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of random seeds from [here](https://www.random.org/bytes/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# old seeds: [0xDEADF00D, 0xFABACABA, 0x738E2A0B, 0x6508C9F4, 0xFBA15A24,\n",
    "#             0x6DAEDD6B, 0xC05DE9CE, 0xFC3021A6,]\n",
    "\n",
    "master_seeds = [0x2357D9C1, 0x4FE1E92D, 0xDC9F3966, 0x18E04C68, 0xEC864D20,\n",
    "                0x8A63D1FE, 0xACBC4A59, 0x24F187FF, 0x97D37D23, 0x87AFB2AE,\n",
    "                0x3CADD47C, 0xFD6851AC, 0x77B6FE1A, 0xCBB3EBA1, 0x024F215B,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Monte Carlo experiemnt is run in parallel batches, with each\n",
    "initialized to a randomly picked seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_RAND_SEED = np.iinfo(np.int32).max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hermite experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed 24F215B\n"
     ]
    }
   ],
   "source": [
    "from crossing_tree.processes import HermiteProcess\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, n_downsample = 1 << 19, 1 << 4\n",
    "degrees, methods = [2, 3, 4], [\"med\", \"std\", \"iqr\",]\n",
    "hurst_exponents = [0.6, 0.7, 0.8, 0.9,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment for the Hermite process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRP2_16-524288-0.600-125x8 467.902sec. ../results/HRP2_16-524288-0.600-125x8_20161011-220307.gz\n",
      "HRP2_16-524288-0.700-125x8 480.998sec. ../results/HRP2_16-524288-0.700-125x8_20161011-221116.gz\n",
      "HRP2_16-524288-0.800-125x8 498.085sec. ../results/HRP2_16-524288-0.800-125x8_20161011-221943.gz\n",
      "HRP2_16-524288-0.900-125x8 534.033sec. ../results/HRP2_16-524288-0.900-125x8_20161011-222846.gz\n",
      "HRP3_16-524288-0.600-125x8 516.212sec. ../results/HRP3_16-524288-0.600-125x8_20161011-223733.gz\n",
      "HRP3_16-524288-0.700-125x8 533.479sec. ../results/HRP3_16-524288-0.700-125x8_20161011-224634.gz\n",
      "HRP3_16-524288-0.800-125x8 551.205sec. ../results/HRP3_16-524288-0.800-125x8_20161011-225554.gz\n",
      "HRP3_16-524288-0.900-125x8 579.142sec. ../results/HRP3_16-524288-0.900-125x8_20161011-230544.gz\n",
      "HRP4_16-524288-0.600-125x8 570.336sec. ../results/HRP4_16-524288-0.600-125x8_20161011-231525.gz\n",
      "HRP4_16-524288-0.700-125x8 597.338sec. ../results/HRP4_16-524288-0.700-125x8_20161011-232530.gz\n",
      "HRP4_16-524288-0.800-125x8 628.181sec. ../results/HRP4_16-524288-0.800-125x8_20161011-233609.gz\n",
      "HRP4_16-524288-0.900-125x8 651.637sec. ../results/HRP4_16-524288-0.900-125x8_20161011-234711.gz\n"
     ]
    }
   ],
   "source": [
    "if skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for degree_ in degrees:\n",
    "        for hurst_ in hurst_exponents:\n",
    "            name_ = \"HRP%d_%d-%d-%0.3f-%dx%d\"%(degree_, n_downsample, n_samples, hurst_, n_per_batch, n_batches)\n",
    "            print name_,\n",
    "\n",
    "            # Schedule the experiments\n",
    "            seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "            schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                             HermiteProcess(N=n_samples,\n",
    "                                                            degree=degree_,\n",
    "                                                            n_downsample=n_downsample,\n",
    "                                                            hurst=hurst_,\n",
    "                                                            random_state=seed_))\n",
    "                                        for seed_ in seeds)\n",
    "\n",
    "            # Run the experiment and collect the results\n",
    "            tick_ = time.time()\n",
    "            experiment_ids = list()\n",
    "            results_ = {method: list() for method in methods}\n",
    "            for id_, dict_ in par_(schedule_):\n",
    "                experiment_ids.append(id_)\n",
    "                for method in methods:\n",
    "                    results_[method].extend(dict_[method])\n",
    "            results = {key_: collect_structural_statistics(list_)\n",
    "                       for key_, list_ in results_.iteritems()}\n",
    "            tock_ = time.time()\n",
    "\n",
    "            # Save the results and log\n",
    "            filename_ = save((tick_, tock_, experiment_ids, results), \"../results/\", name_)\n",
    "            print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weierstrass experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed CBB3EBA1\n"
     ]
    }
   ],
   "source": [
    "from crossing_tree.processes import WeierstrassFunction\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, lambda_0 = 1 << 23, 1.2\n",
    "methods = [\"med\", \"std\", \"iqr\",]\n",
    "\n",
    "holder_exponents = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experimnet for the random Weierstrass function $[0, 1]\\mapsto \\mathbb{R}$:\n",
    "$$ W_H(t) = \\sum_{k\\geq 0} \\lambda_0^{-k H} \\bigl(\\cos(2 \\pi \\lambda_0^k t + \\phi_k) - \\cos \\phi_k\\bigr)\\,, $$\n",
    "with $(\\phi_k)_{k\\geq0} \\sim \\mathbb{U}[0, 2\\pi]$, and $\\lambda_0 > 1$ -- the fundamental harmonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEI_1.2-8388608-0.500-125x8 14294.285sec. ../results/WEI_1.2-8388608-0.500-125x8_20161012-034536.gz\n",
      "WEI_1.2-8388608-0.600-125x8 14508.481sec. ../results/WEI_1.2-8388608-0.600-125x8_20161012-074732.gz\n",
      "WEI_1.2-8388608-0.700-125x8 14778.991sec. ../results/WEI_1.2-8388608-0.700-125x8_20161012-115401.gz\n",
      "WEI_1.2-8388608-0.800-125x8 15123.950sec. ../results/WEI_1.2-8388608-0.800-125x8_20161012-160615.gz\n",
      "WEI_1.2-8388608-0.900-125x8 15374.462sec. ../results/WEI_1.2-8388608-0.900-125x8_20161012-202241.gz\n",
      "WEI_1.2-8388608-0.950-125x8 15571.504sec. ../results/WEI_1.2-8388608-0.950-125x8_20161013-004225.gz\n",
      "WEI_1.2-8388608-0.990-125x8 15642.739sec. ../results/WEI_1.2-8388608-0.990-125x8_20161013-050321.gz\n"
     ]
    }
   ],
   "source": [
    "if skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for holder_ in holder_exponents:\n",
    "        name_ = \"WEI_%g-%d-%0.3f-%dx%d\"%(lambda_0, n_samples, holder_, n_per_batch, n_batches)\n",
    "        print name_,\n",
    "\n",
    "        # Schedule the experiments\n",
    "        seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "        schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                         WeierstrassFunction(N=n_samples,\n",
    "                                                             lambda_0=lambda_0,\n",
    "                                                             holder=holder_,\n",
    "                                                             random_state=seed_,\n",
    "                                                             one_sided=False))\n",
    "                                    for seed_ in seeds)\n",
    "\n",
    "        # Run the experiment and collect the results\n",
    "        tick_ = time.time()\n",
    "        experiment_ids = list()\n",
    "        results_ = {method: list() for method in methods}\n",
    "        for id_, dict_ in par_(schedule_):\n",
    "            experiment_ids.append(id_)\n",
    "            for method in methods:\n",
    "                results_[method].extend(dict_[method])\n",
    "        results = {key_: collect_structural_statistics(list_)\n",
    "                   for key_, list_ in results_.iteritems()}\n",
    "        tock_ = time.time()\n",
    "\n",
    "        # Save the results and log\n",
    "        filename_ = save((tick_, tock_, experiment_ids, results), \"../results/\", name_)\n",
    "        print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fBM experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed 77B6FE1A\n"
     ]
    }
   ],
   "source": [
    "from crossing_tree.processes import FractionalBrownianMotion\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, methods = 1 << 23, [\"med\", \"std\", \"iqr\",]\n",
    "hurst_exponents = [0.500, 0.550, 0.600, 0.650, 0.700, 0.750, 0.800, 0.850, 0.900,\n",
    "                   0.910, 0.915, 0.920, 0.925, 0.930, 0.935, 0.940, 0.945, 0.950,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment for the Fractional Brownian Motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBM-8388608-0.500-125x8 2031.947sec. ../results/FBM-8388608-0.500-125x8_20161013-053727.gz\n",
      "FBM-8388608-0.550-125x8 2154.489sec. ../results/FBM-8388608-0.550-125x8_20161013-061329.gz\n",
      "FBM-8388608-0.600-125x8 2277.297sec. ../results/FBM-8388608-0.600-125x8_20161013-065135.gz\n",
      "FBM-8388608-0.650-125x8 2392.415sec. ../results/FBM-8388608-0.650-125x8_20161013-073137.gz\n",
      "FBM-8388608-0.700-125x8 2521.615sec. ../results/FBM-8388608-0.700-125x8_20161013-081349.gz\n",
      "FBM-8388608-0.750-125x8 2637.187sec. ../results/FBM-8388608-0.750-125x8_20161013-085757.gz\n",
      "FBM-8388608-0.800-125x8 2762.201sec. ../results/FBM-8388608-0.800-125x8_20161013-094410.gz\n",
      "FBM-8388608-0.850-125x8 2891.440sec. ../results/FBM-8388608-0.850-125x8_20161013-103234.gz\n",
      "FBM-8388608-0.900-125x8 3011.573sec. ../results/FBM-8388608-0.900-125x8_20161013-112257.gz\n",
      "FBM-8388608-0.910-125x8 3046.946sec. ../results/FBM-8388608-0.910-125x8_20161013-121358.gz\n",
      "FBM-8388608-0.915-125x8 3052.126sec. ../results/FBM-8388608-0.915-125x8_20161013-130503.gz\n",
      "FBM-8388608-0.920-125x8 3094.760sec. ../results/FBM-8388608-0.920-125x8_20161013-135652.gz\n",
      "FBM-8388608-0.925-125x8 3111.448sec. ../results/FBM-8388608-0.925-125x8_20161013-144857.gz\n",
      "FBM-8388608-0.930-125x8 3135.191sec. ../results/FBM-8388608-0.930-125x8_20161013-154126.gz\n",
      "FBM-8388608-0.935-125x8 3145.568sec. ../results/FBM-8388608-0.935-125x8_20161013-163405.gz\n",
      "FBM-8388608-0.940-125x8 3130.568sec. ../results/FBM-8388608-0.940-125x8_20161013-172630.gz\n",
      "FBM-8388608-0.945-125x8 3132.812sec. ../results/FBM-8388608-0.945-125x8_20161013-181857.gz\n",
      "FBM-8388608-0.950-125x8 3133.880sec. ../results/FBM-8388608-0.950-125x8_20161013-191125.gz\n"
     ]
    }
   ],
   "source": [
    "if skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for hurst_ in hurst_exponents:\n",
    "        name_ = \"FBM-%d-%0.3f-%dx%d\"%(n_samples, hurst_, n_per_batch, n_batches)\n",
    "        print name_,\n",
    "\n",
    "        # Schedule the experiments\n",
    "        seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "        schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                         FractionalBrownianMotion(N=n_samples,\n",
    "                                                                  hurst=hurst_,\n",
    "                                                                  random_state=seed_))\n",
    "                                    for seed_ in seeds)\n",
    "\n",
    "        # Run the experiment and collect the results\n",
    "        tick_ = time.time()\n",
    "        experiment_ids = list()\n",
    "        results_ = {method: list() for method in methods}\n",
    "        for id_, dict_ in par_(schedule_):\n",
    "            experiment_ids.append(id_)\n",
    "            for method in methods:\n",
    "                results_[method].extend(dict_[method])\n",
    "        results = {key_: collect_structural_statistics(list_)\n",
    "                   for key_, list_ in results_.iteritems()}\n",
    "        tock_ = time.time()\n",
    "\n",
    "        # Save the results and log\n",
    "        filename_ = save((tick_, tock_, experiment_ids, results), \"../results/\", name_)\n",
    "        print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weierstrass experiment pt.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed FD6851AC\n"
     ]
    }
   ],
   "source": [
    "from crossing_tree.processes import WeierstrassFunction\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, lambda_0 = 1 << 23, 1.2\n",
    "methods = [\"med\", \"std\", \"iqr\",]\n",
    "\n",
    "holder_exponents = [0.910, 0.915, 0.920, 0.925,\n",
    "                    0.930, 0.935, 0.940, 0.945,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experimnet for the random Weierstrass function $[0, 1]\\mapsto \\mathbb{R}$:\n",
    "$$ W_H(t) = \\sum_{k\\geq 0} \\lambda_0^{-k H} \\bigl(\\cos(2 \\pi \\lambda_0^k t + \\phi_k) - \\cos \\phi_k\\bigr)\\,, $$\n",
    "with $(\\phi_k)_{k\\geq0} \\sim \\mathbb{U}[0, 2\\pi]$, and $\\lambda_0 > 1$ -- the fundamental harmonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEI_1.2-8388608-0.910-125x8 15308.835sec. ../results/WEI_1.2-8388608-0.910-125x8_20161014-013511.gz\n",
      "WEI_1.2-8388608-0.915-125x8 15404.482sec. ../results/WEI_1.2-8388608-0.915-125x8_20161014-055208.gz\n",
      "WEI_1.2-8388608-0.920-125x8 15420.649sec. ../results/WEI_1.2-8388608-0.920-125x8_20161014-100922.gz\n",
      "WEI_1.2-8388608-0.925-125x8 15478.133sec. ../results/WEI_1.2-8388608-0.925-125x8_20161014-142733.gz\n",
      "WEI_1.2-8388608-0.930-125x8 15618.317sec. ../results/WEI_1.2-8388608-0.930-125x8_20161014-184805.gz\n",
      "WEI_1.2-8388608-0.935-125x8 15464.825sec. ../results/WEI_1.2-8388608-0.935-125x8_20161014-230603.gz\n",
      "WEI_1.2-8388608-0.940-125x8 15349.082sec. ../results/WEI_1.2-8388608-0.940-125x8_20161015-032205.gz\n",
      "WEI_1.2-8388608-0.945-125x8 15335.909sec. ../results/WEI_1.2-8388608-0.945-125x8_20161015-073754.gz\n"
     ]
    }
   ],
   "source": [
    "if skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for holder_ in holder_exponents:\n",
    "        name_ = \"WEI_%g-%d-%0.3f-%dx%d\"%(lambda_0, n_samples, holder_, n_per_batch, n_batches)\n",
    "        print name_,\n",
    "\n",
    "        # Schedule the experiments\n",
    "        seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "        schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                         WeierstrassFunction(N=n_samples,\n",
    "                                                             lambda_0=lambda_0,\n",
    "                                                             holder=holder_,\n",
    "                                                             random_state=seed_,\n",
    "                                                             one_sided=False))\n",
    "                                    for seed_ in seeds)\n",
    "\n",
    "        # Run the experiment and collect the results\n",
    "        tick_ = time.time()\n",
    "        experiment_ids = list()\n",
    "        results_ = {method: list() for method in methods}\n",
    "        for id_, dict_ in par_(schedule_):\n",
    "            experiment_ids.append(id_)\n",
    "            for method in methods:\n",
    "                results_[method].extend(dict_[method])\n",
    "        results = {key_: collect_structural_statistics(list_)\n",
    "                   for key_, list_ in results_.iteritems()}\n",
    "        tock_ = time.time()\n",
    "\n",
    "        # Save the results and log\n",
    "        filename_ = save((tick_, tock_, experiment_ids, results), \"../results/\", name_)\n",
    "        print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weierstrass experiment pt.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree.processes import WeierstrassFunction\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, lambda_0 = 1 << 23, 1.7\n",
    "methods = [\"med\", \"std\", \"iqr\",]\n",
    "\n",
    "holder_exponents = [0.500, 0.550, 0.600, 0.650, 0.700, 0.750, 0.800, 0.850, 0.900,\n",
    "                    0.910, 0.915, 0.920, 0.925, 0.930, 0.935, 0.940, 0.945, 0.950,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experimnet for the random Weierstrass function $[0, 1]\\mapsto \\mathbb{R}$:\n",
    "$$ W_H(t) = \\sum_{k\\geq 0} \\lambda_0^{-k H} \\bigl(\\cos(2 \\pi \\lambda_0^k t + \\phi_k) - \\cos \\phi_k\\bigr)\\,, $$\n",
    "with $(\\phi_k)_{k\\geq0} \\sim \\mathbb{U}[0, 2\\pi]$, and $\\lambda_0 > 1$ -- the fundamental harmonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for holder_ in holder_exponents:\n",
    "        name_ = \"WEI_%g-%d-%0.3f-%dx%d\"%(lambda_0, n_samples, holder_, n_per_batch, n_batches)\n",
    "        print name_,\n",
    "\n",
    "        # Schedule the experiments\n",
    "        seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "        schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                         WeierstrassFunction(N=n_samples,\n",
    "                                                             lambda_0=lambda_0,\n",
    "                                                             holder=holder_,\n",
    "                                                             random_state=seed_,\n",
    "                                                             one_sided=False))\n",
    "                                    for seed_ in seeds)\n",
    "\n",
    "        # Run the experiment and collect the results\n",
    "        tick_ = time.time()\n",
    "        experiment_ids = list()\n",
    "        results_ = {method: list() for method in methods}\n",
    "        for id_, dict_ in par_(schedule_):\n",
    "            experiment_ids.append(id_)\n",
    "            for method in methods:\n",
    "                results_[method].extend(dict_[method])\n",
    "        results = {key_: collect_structural_statistics(list_)\n",
    "                   for key_, list_ in results_.iteritems()}\n",
    "        tock_ = time.time()\n",
    "\n",
    "        # Save the results and log\n",
    "        filename_ = save((tick_, tock_, experiment_ids, results), \"../results/\", name_)\n",
    "        print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
