{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Monte Carlo experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A handy routines to store and recover python objects, in particular, the experiment resutls dictionaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time, gzip\n",
    "import os, cPickle\n",
    "\n",
    "def save(obj, path, prefix=None):\n",
    "    prefix_ = \"\" if prefix is None else \"%s_\"%(prefix,)\n",
    "    filename_ = os.path.join(path, \"%s%s.gz\"%(prefix_, time.strftime(\"%Y%m%d-%H%M%S\"),))\n",
    "    with gzip.open(filename_, \"wb+\", 9) as fout_:\n",
    "        cPickle.dump(obj, fout_)\n",
    "    return filename_\n",
    "\n",
    "def load(filename):\n",
    "    with gzip.open(filename, \"rb\") as f:\n",
    "        return cPickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree import crossing_tree\n",
    "\n",
    "def path_analyze(X, T, scale=1.0):\n",
    "    xi, ti, offspring, Vnk, Znk, Wnk = crossing_tree(X, T, scale=scale, origin=X[0])\n",
    "    # Sanity check.\n",
    "    # for j in xrange(len(Znk)):\n",
    "    #     assert np.allclose(2 * Vnk[j][:, :2].sum(axis=1) + 2, Znk[j])\n",
    "\n",
    "    # Nn[n] -- the total number of crossings of grid with spacing \\delta 2^n\n",
    "    Nn = np.r_[len(xi), [len(index_) for index_ in offspring]] - 1\n",
    "\n",
    "    # Dnk[n][k] -- the total number of crossings of grid \\delta 2^{n+1}\n",
    "    #  with exactly 2(k+1) subcrossings of grid \\delta 2^n.\n",
    "    freq = [np.bincount(Zk)[2::2] for Zk in Znk]\n",
    "    Dnk = np.zeros((len(Znk), max(len(f) for f in freq)), np.int)\n",
    "    for l, f in enumerate(freq):\n",
    "        Dnk[l, :len(f)] = f\n",
    "\n",
    "    # Vnde[n][d][e] -- the total number of up-down(e=0) and down-up(e=1)\n",
    "    #  excursions in a downward (d=0) or upward (d=1) crossing of level\n",
    "    #  n+1\n",
    "    Vnde = np.array([(Vk[Vk[:, 2] < 0, :2].sum(axis=0),\n",
    "                      Vk[Vk[:, 2] > 0, :2].sum(axis=0))\n",
    "                     for Vk in Vnk], dtype=np.int)\n",
    "\n",
    "    # Wnp[n][p] -- the p-th empirical quantile of the n-th level crossing\n",
    "    #  durations.\n",
    "    prc = [0.1, 0.5, 1.0, 2.5, 5.0, 10, 25, 50, 75, 90, 95, 97.5, 99, 99.5, 99.9]\n",
    "    empty_ = np.full_like(prc, np.nan)\n",
    "    Wnp = np.stack([np.percentile(Wk, prc) if len(Wk) > 0 else empty_ for Wk in Wnk])\n",
    "\n",
    "    # The average crossing duration and its standard deviation\n",
    "    Wavgn = np.array([np.mean(Wk) if len(Wk) > 0 else np.nan for Wk in Wnk])\n",
    "    Wstdn = np.array([np.std(Wk) if len(Wk) > 0 else np.nan for Wk in Wnk])\n",
    "    return scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect a list of results returned by path_analyze into aligned data tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect(results):\n",
    "    results = list(results)\n",
    "\n",
    "    scale_m = np.array([scale for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results])\n",
    "\n",
    "    Nmn = [Nn for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results]\n",
    "    L = max(Nn.shape[0] for Nn in Nmn)\n",
    "    Nmn = np.stack([np.pad(Nn, (0, L - Nn.shape[0]), mode=\"constant\").astype(np.float)\n",
    "                    for Nn in Nmn])\n",
    "\n",
    "    Dmnk = [Dnk for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results]\n",
    "    K = max(Dnk.shape[1] for Dnk in Dmnk)\n",
    "    Dmnk = np.stack([np.pad(Dnk, ((0, L - 1 - Dnk.shape[0]), (0, K - Dnk.shape[1])),\n",
    "                            mode=\"constant\").astype(np.float)\n",
    "                     for Dnk in Dmnk])\n",
    "\n",
    "    Wmnp = np.stack([np.pad(Wnp.astype(np.float), ((0, L - 1 - Wnp.shape[0]), (0, 0)),\n",
    "                            mode=\"constant\", constant_values=np.nan)\n",
    "                     for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results])\n",
    "\n",
    "    Vmnde = np.stack([np.pad(Vnde.astype(np.float), ((0, L - 1 - Vnde.shape[0]),\n",
    "                                                     (0, 0), (0, 0)),\n",
    "                             mode=\"constant\", constant_values=np.nan)\n",
    "                      for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results])\n",
    "\n",
    "    Wavgmn = np.stack([np.pad(Wavgn.astype(np.float), (0, L - 1 - Wavgn.shape[0]),\n",
    "                              mode=\"constant\", constant_values=np.nan)\n",
    "                       for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results])\n",
    "\n",
    "    Wstdmn = np.stack([np.pad(Wstdn.astype(np.float), (0, L - 1 - Wstdn.shape[0]),\n",
    "                              mode=\"constant\", constant_values=np.nan)\n",
    "                       for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results])\n",
    "\n",
    "    return scale_m, Nmn, Dmnk, Vmnde, Wmnp, Wavgmn, Wstdmn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function implementing various delta choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def get_delta_method(delta=1.0):\n",
    "    if isinstance(delta, str):\n",
    "        if delta == \"std\":\n",
    "            # the standard deviation of increments\n",
    "            delta_ = lambda X: np.diff(X).std()\n",
    "        elif delta == \"med\":\n",
    "            # Use the median absolute difference [Jones, Rolls; 2009] p. 11 (arxiv:0911.5204v2)\n",
    "            delta_ = lambda X: np.median(np.abs(np.diff(X)))\n",
    "        elif delta == \"iqr\":\n",
    "            # Interquartile range\n",
    "            delta_ = lambda X: np.subtract(*np.percentile(np.diff(X), [75, 25]))\n",
    "        elif delta == \"rng\":\n",
    "            # Use the range estimate as suggested by Geoffrey on 2015-05-28\n",
    "            warnings.warn(\"\"\"Use of `range`-based grid resolution \"\"\"\n",
    "                          \"\"\"is discouraged since it may cause misaligned \"\"\"\n",
    "                          \"\"\"crossing trees.\"\"\", RuntimeWarning)\n",
    "            delta_ = lambda X: (X.max() - X.min()) / (2**12)\n",
    "        else:\n",
    "            raise ValueError(\"\"\"Invalid `delta` setting. Accepted values \"\"\"\n",
    "                             \"\"\"are: [`iqr`, `std`, `med`, `rng`].\"\"\")\n",
    "    elif isinstance(delta, float) and delta > 0:\n",
    "        delta_ = lambda X: delta\n",
    "    else:\n",
    "        raise TypeError(\"\"\"`delta` must be either a float, or a method \"\"\"\n",
    "                        \"\"\"identifier.\"\"\")\n",
    "    return delta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An MC experiment kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def experiment(experiment_id, n_replications, methods, generator):\n",
    "    generator = clone(generator)\n",
    "    generator.start()\n",
    "\n",
    "    deltas = [get_delta_method(method_) for method_ in methods]\n",
    "\n",
    "    results = {method_: list() for method_ in methods}\n",
    "    for j in xrange(n_replications):\n",
    "        T, X = generator.draw()\n",
    "\n",
    "        # Apply all methods to the same sample path.\n",
    "        for delta, method in zip(deltas, methods):\n",
    "            results[method].append(path_analyze(X, T, scale=delta(X)))\n",
    "\n",
    "    generator.finish()\n",
    "\n",
    "    return experiment_id, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of random seeds from [here](https://www.random.org/bytes/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# old seeds: [0xDEADF00D, 0xFABACABA, 0x738E2A0B, 0x6508C9F4, 0xFBA15A24,\n",
    "#             0x6DAEDD6B, 0xC05DE9CE, 0xFC3021A6,]\n",
    "\n",
    "master_seeds = [0x2357D9C1, 0x4FE1E92D, 0xDC9F3966, 0x18E04C68, 0xEC864D20,\n",
    "                0x8A63D1FE, 0xACBC4A59, 0x24F187FF, 0x97D37D23, 0x87AFB2AE,\n",
    "                0x3CADD47C, 0xFD6851AC, 0x77B6FE1A, 0xCBB3EBA1, 0x024F215B,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Monte Carlo experiemnt is run in parallel batches, with each\n",
    "initialized to a randomly picked seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_RAND_SEED = np.iinfo(np.int32).max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hermite experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree.processes import HermiteProcess\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, n_downsample = 1 << 19, 1 << 4\n",
    "degrees, methods = [2, 3, 4], [\"med\", \"std\", \"iqr\",]\n",
    "hurst_exponents = [0.6, 0.7, 0.8, 0.9, 0.95,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment for the Hermite process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "for degree_ in degrees:\n",
    "    for hurst_ in hurst_exponents:\n",
    "        name_ = \"HRP%d_%d-%d-%0.3f-%dx%d\"%(degree_, n_downsample, n_samples, hurst_, n_per_batch, n_batches)\n",
    "        print name_,\n",
    "\n",
    "        # Schedule the experiments\n",
    "        seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "        schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                         HermiteProcess(N=n_samples,\n",
    "                                                        degree=degree_,\n",
    "                                                        n_downsample=n_downsample,\n",
    "                                                        hurst=hurst_,\n",
    "                                                        random_state=seed_))\n",
    "                                    for seed_ in seeds)\n",
    "\n",
    "        # Run the experiment and collect the results\n",
    "        tick_ = time.time()\n",
    "        experiment_ids = list()\n",
    "        results_ = {method: list() for method in methods}\n",
    "        for id_, dict_ in par_(schedule_):\n",
    "            experiment_ids.append(id_)\n",
    "            for method in methods:\n",
    "                results_[method].extend(dict_[method])\n",
    "        results = {key_: collect(list_) for key_, list_ in results_.iteritems()}\n",
    "        tock_ = time.time()\n",
    "\n",
    "        # Save the results and log\n",
    "        filename_ = save((tick_, tock_, experiment_ids, results), \"../results/\", name_)\n",
    "        print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weierstrass experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree.processes import WeierstrassFunction\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, lambda_0 = 1 << 23, 1.2\n",
    "methods = [\"med\", \"std\", \"iqr\",]\n",
    "\n",
    "holder_exponents = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experimnet for the random Weierstrass function $[0, 1]\\mapsto \\mathbb{R}$:\n",
    "$$ W_H(t) = \\sum_{k\\geq 0} \\lambda_0^{-k H} \\bigl(\\cos(2 \\pi \\lambda_0^k t + \\phi_k) - \\cos \\phi_k\\bigr)\\,, $$\n",
    "with $(\\phi_k)_{k\\geq0} \\sim \\mathbb{U}[0, 2\\pi]$, and $\\lambda_0 > 1$ -- the fundamental harmonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "for holder_ in holder_exponents:\n",
    "    name_ = \"WEI_%g-%d-%0.3f-%dx%d\"%(lambda_0, n_samples, holder_, n_per_batch, n_batches)\n",
    "    print name_,\n",
    "\n",
    "    # Schedule the experiments\n",
    "    seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "    schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                     WeierstrassFunction(N=n_samples,\n",
    "                                                         lambda_0=lambda_0,\n",
    "                                                         holder=holder_,\n",
    "                                                         random_state=seed_,\n",
    "                                                         one_sided=False))\n",
    "                                for seed_ in seeds)\n",
    "\n",
    "    # Run the experiment and collect the results\n",
    "    tick_ = time.time()\n",
    "    experiment_ids = list()\n",
    "    results_ = {method: list() for method in methods}\n",
    "    for id_, dict_ in par_(schedule_):\n",
    "        experiment_ids.append(id_)\n",
    "        for method in methods:\n",
    "            results_[method].extend(dict_[method])\n",
    "    results = {key_: collect(list_) for key_, list_ in results_.iteritems()}\n",
    "    tock_ = time.time()\n",
    "\n",
    "    # Save the results and log\n",
    "    filename_ = save((tick_, tock_, experiment_ids, results), \"../results/\", name_)\n",
    "    print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fBM experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree.processes import FractionalBrownianMotion\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, methods = 1 << 23, [\"med\", \"std\", \"iqr\",]\n",
    "hurst_exponents = [0.500, 0.550, 0.600, 0.650, 0.700, 0.750, 0.800, 0.850, 0.900,\n",
    "                   0.910, 0.915, 0.920, 0.925, 0.930, 0.935, 0.940, 0.945, 0.950,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment for the Fractional Brownian Motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "for hurst_ in hurst_exponents:\n",
    "    name_ = \"FBM-%d-%0.3f-%dx%d\"%(n_samples, hurst_, n_per_batch, n_batches)\n",
    "    print name_,\n",
    "\n",
    "    # Schedule the experiments\n",
    "    seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "    schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                     FractionalBrownianMotion(N=n_samples,\n",
    "                                                              hurst=hurst_,\n",
    "                                                              random_state=seed_))\n",
    "                                for seed_ in seeds)\n",
    "\n",
    "    # Run the experiment and collect the results\n",
    "    tick_ = time.time()\n",
    "    experiment_ids = list()\n",
    "    results_ = {method: list() for method in methods}\n",
    "    for id_, dict_ in par_(schedule_):\n",
    "        experiment_ids.append(id_)\n",
    "        for method in methods:\n",
    "            results_[method].extend(dict_[method])\n",
    "    results = {key_: collect(list_) for key_, list_ in results_.iteritems()}\n",
    "    tock_ = time.time()\n",
    "\n",
    "    # Save the results and log\n",
    "    filename_ = save((tick_, tock_, experiment_ids, results), \"../results/\", name_)\n",
    "    print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
