{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Monte Carlo experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A handy routines to store and recover python objects, in particular, the experiment resutls dictionaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time, gzip\n",
    "import os, cPickle\n",
    "\n",
    "def save(obj, path, prefix=None):\n",
    "    prefix_ = \"\" if prefix is None else \"%s_\"%(prefix,)\n",
    "    filename_ = os.path.join(path, \"%s%s.gz\"%(prefix_, time.strftime(\"%Y%m%d-%H%M%S\"),))\n",
    "    with gzip.open(filename_, \"wb+\", 9) as fout_:\n",
    "        cPickle.dump(obj, fout_)\n",
    "    return filename_\n",
    "\n",
    "def load(filename):\n",
    "    with gzip.open(filename, \"rb\") as f:\n",
    "        return cPickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree import structural_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect a list of results returned by path_analyze into aligned data tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree import collect_structural_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function implementing various delta choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def get_delta_method(delta=1.0):\n",
    "    if isinstance(delta, str):\n",
    "        if delta == \"std\":\n",
    "            # the standard deviation of increments\n",
    "            delta_ = lambda X: np.diff(X).std()\n",
    "        elif delta == \"med\":\n",
    "            # Use the median absolute difference [Jones, Rolls; 2009] p. 11 (arxiv:0911.5204v2)\n",
    "            delta_ = lambda X: np.median(np.abs(np.diff(X)))\n",
    "        elif delta == \"mean\":\n",
    "            # Use the mean absolute difference\n",
    "            delta_ = lambda X: np.mean(np.abs(np.diff(X)))\n",
    "        elif delta == \"iqr\":\n",
    "            # Interquartile range\n",
    "            delta_ = lambda X: np.subtract(*np.percentile(np.diff(X), [75, 25]))\n",
    "        elif delta == \"rng\":\n",
    "            # Use the range estimate as suggested by Geoffrey on 2015-05-28\n",
    "            warnings.warn(\"\"\"Use of `range`-based grid resolution \"\"\"\n",
    "                          \"\"\"is discouraged since it may cause misaligned \"\"\"\n",
    "                          \"\"\"crossing trees.\"\"\", RuntimeWarning)\n",
    "            delta_ = lambda X: (X.max() - X.min()) / (2**12)\n",
    "        else:\n",
    "            raise ValueError(\"\"\"Invalid `delta` setting. Accepted values \"\"\"\n",
    "                             \"\"\"are: [`iqr`, `std`, `med`, `rng`, `mean`].\"\"\")\n",
    "    elif isinstance(delta, float) and delta > 0:\n",
    "        delta_ = lambda X: delta\n",
    "    else:\n",
    "        raise TypeError(\"\"\"`delta` must be either a float, or a method \"\"\"\n",
    "                        \"\"\"identifier.\"\"\")\n",
    "    return delta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An MC experiment kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def experiment(experiment_id, n_replications, methods, generator):\n",
    "    generator = clone(generator)\n",
    "    generator.start()\n",
    "\n",
    "    deltas = [get_delta_method(method_) for method_ in methods]\n",
    "\n",
    "    results = {method_: list() for method_ in methods}\n",
    "    for j in xrange(n_replications):\n",
    "        T, X = generator.draw()\n",
    "\n",
    "        # Apply all methods to the same sample path.\n",
    "        for delta, method in zip(deltas, methods):\n",
    "            result_ = structural_statistics(X, T, scale=delta(X), origin=X[0])\n",
    "            results[method].append(result_)\n",
    "\n",
    "    generator.finish()\n",
    "\n",
    "    return experiment_id, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of random seeds from [here](https://www.random.org/bytes/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra random seeds should be prepended to the array.\n",
    "master_seeds = [0xB5BC12B7, 0x3298B667, 0xC54247B6, 0x0A868C68, 0x3AC964A8,\n",
    "                0x6F82F10A, 0x8BF7DA79, 0x48009E58, 0x7A908C10, 0x91A42FF2,\n",
    "                0x3C5E5D39, 0x7A72D405, 0x6D47DBAA, 0x819028DE, 0xA9A5642B,\n",
    "                0x04DFFE11, 0x8A4AC197, 0xFED5E293, 0xC43A534A, 0xAC2A48CE,\n",
    "                0x7B3E134E, 0xCC05D35A, 0x14B0DBDF, 0x1A4BD8DD, 0x1B319B92,\n",
    "                0xD9A6BDD2, 0xF618C88E, 0xCB9055BA, 0xD262541D, 0xB3DB7B23,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Monte Carlo experiemnt is run in parallel batches, with each\n",
    "initialized to a randomly picked seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_RAND_SEED = np.iinfo(np.int32).max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder to store the results in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"../results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fBM experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed B3DB7B23\n"
     ]
    }
   ],
   "source": [
    "from crossing_tree.processes import FractionalBrownianMotion\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, methods = 1 << 23, [\"med\", \"std\", \"iqr\", \"mean\",]\n",
    "hurst_exponents = [0.500, 0.550, 0.600, 0.650, 0.700, 0.750, 0.800, 0.850, 0.900,\n",
    "                   0.910, 0.915, 0.920, 0.925, 0.930, 0.935, 0.940, 0.945, 0.950,\n",
    "                   0.990,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment for the Fractional Brownian Motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBM-8388608-0.500-125x8 1030.696sec. ../results/FBM-8388608-0.500-125x8_20161019-214206.gz\n",
      "FBM-8388608-0.550-125x8 1064.368sec. ../results/FBM-8388608-0.550-125x8_20161019-220002.gz\n",
      "FBM-8388608-0.600-125x8 1105.569sec. ../results/FBM-8388608-0.600-125x8_20161019-221839.gz\n",
      "FBM-8388608-0.650-125x8 1156.223sec. ../results/FBM-8388608-0.650-125x8_20161019-223807.gz\n",
      "FBM-8388608-0.700-125x8 1200.116sec. ../results/FBM-8388608-0.700-125x8_20161019-225821.gz\n",
      "FBM-8388608-0.750-125x8 1249.725sec. ../results/FBM-8388608-0.750-125x8_20161019-231924.gz\n",
      "FBM-8388608-0.800-125x8 1311.252sec. ../results/FBM-8388608-0.800-125x8_20161019-234130.gz\n",
      "FBM-8388608-0.850-125x8 1378.502sec. ../results/FBM-8388608-0.850-125x8_20161020-000444.gz\n",
      "FBM-8388608-0.900-125x8 1460.501sec. ../results/FBM-8388608-0.900-125x8_20161020-002921.gz\n",
      "FBM-8388608-0.910-125x8 1481.666sec. ../results/FBM-8388608-0.910-125x8_20161020-005420.gz\n",
      "FBM-8388608-0.915-125x8 1507.095sec. ../results/FBM-8388608-0.915-125x8_20161020-011945.gz\n",
      "FBM-8388608-0.920-125x8 1500.113sec. ../results/FBM-8388608-0.920-125x8_20161020-014503.gz\n",
      "FBM-8388608-0.925-125x8 1509.737sec. ../results/FBM-8388608-0.925-125x8_20161020-021030.gz\n",
      "FBM-8388608-0.930-125x8 1526.663sec. ../results/FBM-8388608-0.930-125x8_20161020-023615.gz\n",
      "FBM-8388608-0.935-125x8 1532.901sec. ../results/FBM-8388608-0.935-125x8_20161020-030206.gz\n",
      "FBM-8388608-0.940-125x8 1548.929sec. ../results/FBM-8388608-0.940-125x8_20161020-032812.gz\n",
      "FBM-8388608-0.945-125x8 1568.060sec. ../results/FBM-8388608-0.945-125x8_20161020-035438.gz\n",
      "FBM-8388608-0.950-125x8 1571.849sec. ../results/FBM-8388608-0.950-125x8_20161020-042109.gz\n",
      "FBM-8388608-0.990-125x8 1977.480sec. ../results/FBM-8388608-0.990-125x8_20161020-045425.gz\n"
     ]
    }
   ],
   "source": [
    "if not skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for hurst_ in hurst_exponents:\n",
    "        name_ = \"FBM-%d-%0.3f-%dx%d\"%(n_samples, hurst_, n_per_batch, n_batches)\n",
    "        print name_,\n",
    "\n",
    "        # Schedule the experiments\n",
    "        seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "        schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                         FractionalBrownianMotion(N=n_samples,\n",
    "                                                                  hurst=hurst_,\n",
    "                                                                  random_state=seed_))\n",
    "                                    for seed_ in seeds)\n",
    "\n",
    "        # Run the experiment and collect the results\n",
    "        tick_ = time.time()\n",
    "        experiment_ids = list()\n",
    "        results_ = {method: list() for method in methods}\n",
    "        for id_, dict_ in par_(schedule_):\n",
    "            experiment_ids.append(id_)\n",
    "            for method in methods:\n",
    "                results_[method].extend(dict_[method])\n",
    "        results = {key_: collect_structural_statistics(list_)\n",
    "                   for key_, list_ in results_.iteritems()}\n",
    "        tock_ = time.time()\n",
    "\n",
    "        # Save the results and log\n",
    "        filename_ = save((tick_, tock_, experiment_ids, results), OUTPUT_PATH, name_)\n",
    "        print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hermite process experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed D262541D\n"
     ]
    }
   ],
   "source": [
    "from crossing_tree.processes import HermiteProcess\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup: use no downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, n_downsample = 1 << 23, 1\n",
    "degrees, methods = [2, 3, 4], [\"med\", \"std\", \"iqr\", \"mean\",]\n",
    "hurst_exponents = [       0.550, 0.600, 0.650, 0.700, 0.750, 0.800, 0.850, 0.900,\n",
    "                   0.910, 0.915, 0.920, 0.925, 0.930, 0.935, 0.940, 0.945, 0.950,\n",
    "                   0.990,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment for the Hermite process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRP2_1-8388608-0.550-125x8 1228.748sec. ../results/HRP2_1-8388608-0.550-125x8_20161020-051513.gz\n",
      "HRP2_1-8388608-0.600-125x8 1250.329sec. ../results/HRP2_1-8388608-0.600-125x8_20161020-053616.gz\n",
      "HRP2_1-8388608-0.650-125x8 1279.614sec. ../results/HRP2_1-8388608-0.650-125x8_20161020-055749.gz\n",
      "HRP2_1-8388608-0.700-125x8 1313.558sec. ../results/HRP2_1-8388608-0.700-125x8_20161020-061956.gz\n",
      "HRP2_1-8388608-0.750-125x8 1360.610sec. ../results/HRP2_1-8388608-0.750-125x8_20161020-064250.gz\n",
      "HRP2_1-8388608-0.800-125x8 1407.357sec. ../results/HRP2_1-8388608-0.800-125x8_20161020-070632.gz\n",
      "HRP2_1-8388608-0.850-125x8 1468.904sec. ../results/HRP2_1-8388608-0.850-125x8_20161020-073117.gz\n",
      "HRP2_1-8388608-0.900-125x8 1540.926sec. ../results/HRP2_1-8388608-0.900-125x8_20161020-075714.gz\n",
      "HRP2_1-8388608-0.910-125x8 1559.643sec. ../results/HRP2_1-8388608-0.910-125x8_20161020-082331.gz\n",
      "HRP2_1-8388608-0.915-125x8 1569.231sec. ../results/HRP2_1-8388608-0.915-125x8_20161020-084958.gz\n",
      "HRP2_1-8388608-0.920-125x8 1579.387sec. ../results/HRP2_1-8388608-0.920-125x8_20161020-091634.gz\n",
      "HRP2_1-8388608-0.925-125x8 1586.647sec. ../results/HRP2_1-8388608-0.925-125x8_20161020-094319.gz\n",
      "HRP2_1-8388608-0.930-125x8 1605.718sec. ../results/HRP2_1-8388608-0.930-125x8_20161020-101022.gz\n",
      "HRP2_1-8388608-0.935-125x8 1607.562sec. ../results/HRP2_1-8388608-0.935-125x8_20161020-103727.gz\n",
      "HRP2_1-8388608-0.940-125x8 1618.805sec. ../results/HRP2_1-8388608-0.940-125x8_20161020-110444.gz\n",
      "HRP2_1-8388608-0.945-125x8 1637.236sec. ../results/HRP2_1-8388608-0.945-125x8_20161020-113219.gz\n",
      "HRP2_1-8388608-0.950-125x8 1650.769sec. ../results/HRP2_1-8388608-0.950-125x8_20161020-120008.gz\n",
      "HRP2_1-8388608-0.990-125x8 2602.469sec. ../results/HRP2_1-8388608-0.990-125x8_20161020-124349.gz\n",
      "HRP3_1-8388608-0.550-125x8 1196.786sec. ../results/HRP3_1-8388608-0.550-125x8_20161020-130405.gz\n",
      "HRP3_1-8388608-0.600-125x8 1220.939sec. ../results/HRP3_1-8388608-0.600-125x8_20161020-132438.gz\n",
      "HRP3_1-8388608-0.650-125x8 1246.558sec. ../results/HRP3_1-8388608-0.650-125x8_20161020-134538.gz\n",
      "HRP3_1-8388608-0.700-125x8 1286.294sec. ../results/HRP3_1-8388608-0.700-125x8_20161020-140718.gz\n",
      "HRP3_1-8388608-0.750-125x8 1319.786sec. ../results/HRP3_1-8388608-0.750-125x8_20161020-142932.gz\n",
      "HRP3_1-8388608-0.800-125x8 1372.569sec. ../results/HRP3_1-8388608-0.800-125x8_20161020-145239.gz\n",
      "HRP3_1-8388608-0.850-125x8 1434.008sec. ../results/HRP3_1-8388608-0.850-125x8_20161020-151649.gz\n",
      "HRP3_1-8388608-0.900-125x8 1520.646sec. ../results/HRP3_1-8388608-0.900-125x8_20161020-154226.gz\n",
      "HRP3_1-8388608-0.910-125x8 1545.850sec. ../results/HRP3_1-8388608-0.910-125x8_20161020-160829.gz\n",
      "HRP3_1-8388608-0.915-125x8 1564.220sec. ../results/HRP3_1-8388608-0.915-125x8_20161020-163451.gz\n",
      "HRP3_1-8388608-0.920-125x8 1572.268sec. ../results/HRP3_1-8388608-0.920-125x8_20161020-170121.gz\n",
      "HRP3_1-8388608-0.925-125x8 1598.104sec. ../results/HRP3_1-8388608-0.925-125x8_20161020-172817.gz\n",
      "HRP3_1-8388608-0.930-125x8 1608.810sec. ../results/HRP3_1-8388608-0.930-125x8_20161020-175523.gz\n",
      "HRP3_1-8388608-0.935-125x8 1628.150sec. ../results/HRP3_1-8388608-0.935-125x8_20161020-182249.gz\n",
      "HRP3_1-8388608-0.940-125x8 1628.498sec. ../results/HRP3_1-8388608-0.940-125x8_20161020-185015.gz\n",
      "HRP3_1-8388608-0.945-125x8 1643.803sec. ../results/HRP3_1-8388608-0.945-125x8_20161020-191757.gz\n",
      "HRP3_1-8388608-0.950-125x8 1665.178sec. ../results/HRP3_1-8388608-0.950-125x8_20161020-194600.gz\n",
      "HRP3_1-8388608-0.990-125x8 2480.600sec. ../results/HRP3_1-8388608-0.990-125x8_20161020-202740.gz\n",
      "HRP4_1-8388608-0.550-125x8 1245.609sec. ../results/HRP4_1-8388608-0.550-125x8_20161020-204845.gz\n",
      "HRP4_1-8388608-0.600-125x8 1273.586sec. ../results/HRP4_1-8388608-0.600-125x8_20161020-211011.gz\n",
      "HRP4_1-8388608-0.650-125x8 1297.205sec. ../results/HRP4_1-8388608-0.650-125x8_20161020-213202.gz\n",
      "HRP4_1-8388608-0.700-125x8 1333.886sec. ../results/HRP4_1-8388608-0.700-125x8_20161020-215429.gz\n",
      "HRP4_1-8388608-0.750-125x8 1374.711sec. ../results/HRP4_1-8388608-0.750-125x8_20161020-221739.gz\n",
      "HRP4_1-8388608-0.800-125x8 1428.631sec. ../results/HRP4_1-8388608-0.800-125x8_20161020-224142.gz\n",
      "HRP4_1-8388608-0.850-125x8 1500.691sec. ../results/HRP4_1-8388608-0.850-125x8_20161020-230658.gz\n",
      "HRP4_1-8388608-0.900-125x8 1574.710sec. ../results/HRP4_1-8388608-0.900-125x8_20161020-233329.gz\n",
      "HRP4_1-8388608-0.910-125x8 1585.898sec. ../results/HRP4_1-8388608-0.910-125x8_20161021-000013.gz\n",
      "HRP4_1-8388608-0.915-125x8 1602.105sec. ../results/HRP4_1-8388608-0.915-125x8_20161021-002712.gz\n",
      "HRP4_1-8388608-0.920-125x8 1610.256sec. ../results/HRP4_1-8388608-0.920-125x8_20161021-005420.gz\n",
      "HRP4_1-8388608-0.925-125x8 1619.469sec. ../results/HRP4_1-8388608-0.925-125x8_20161021-012137.gz\n",
      "HRP4_1-8388608-0.930-125x8 1632.465sec. ../results/HRP4_1-8388608-0.930-125x8_20161021-014908.gz\n",
      "HRP4_1-8388608-0.935-125x8 1641.650sec. ../results/HRP4_1-8388608-0.935-125x8_20161021-021647.gz\n",
      "HRP4_1-8388608-0.940-125x8 1657.949sec. ../results/HRP4_1-8388608-0.940-125x8_20161021-024443.gz\n",
      "HRP4_1-8388608-0.945-125x8 1669.740sec. ../results/HRP4_1-8388608-0.945-125x8_20161021-031251.gz\n",
      "HRP4_1-8388608-0.950-125x8 1690.913sec. ../results/HRP4_1-8388608-0.950-125x8_20161021-034120.gz\n",
      "HRP4_1-8388608-0.990-125x8 2371.750sec. ../results/HRP4_1-8388608-0.990-125x8_20161021-042110.gz\n"
     ]
    }
   ],
   "source": [
    "if not skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for degree_ in degrees:\n",
    "        for hurst_ in hurst_exponents:\n",
    "            name_ = \"HRP%d_%d-%d-%0.3f-%dx%d\"%(degree_, n_downsample, n_samples, hurst_, n_per_batch, n_batches)\n",
    "            print name_,\n",
    "\n",
    "            # Schedule the experiments\n",
    "            seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "            schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                             HermiteProcess(N=n_samples,\n",
    "                                                            degree=degree_,\n",
    "                                                            n_downsample=n_downsample,\n",
    "                                                            hurst=hurst_,\n",
    "                                                            random_state=seed_))\n",
    "                                        for seed_ in seeds)\n",
    "\n",
    "            # Run the experiment and collect the results\n",
    "            tick_ = time.time()\n",
    "            experiment_ids = list()\n",
    "            results_ = {method: list() for method in methods}\n",
    "            for id_, dict_ in par_(schedule_):\n",
    "                experiment_ids.append(id_)\n",
    "                for method in methods:\n",
    "                    results_[method].extend(dict_[method])\n",
    "            results = {key_: collect_structural_statistics(list_)\n",
    "                       for key_, list_ in results_.iteritems()}\n",
    "            tock_ = time.time()\n",
    "\n",
    "            # Save the results and log\n",
    "            filename_ = save((tick_, tock_, experiment_ids, results), OUTPUT_PATH, name_)\n",
    "            print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weierstrass experiment -- $\\lambda_0 = 1.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seed CB9055BA\n"
     ]
    }
   ],
   "source": [
    "from crossing_tree.processes import WeierstrassFunction\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, lambda_0 = 1 << 23, 1.2\n",
    "methods = [\"med\", \"std\", \"iqr\", \"mean\",]\n",
    "holder_exponents = [0.500, 0.550, 0.600, 0.650, 0.700, 0.750, 0.800, 0.850, 0.900,\n",
    "                    0.910, 0.915, 0.920, 0.925, 0.930, 0.935, 0.940, 0.945, 0.950,\n",
    "                    0.990,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experimnet for the random Weierstrass function $[0, 1]\\mapsto \\mathbb{R}$:\n",
    "$$ W_H(t) = \\sum_{k\\geq 0} \\lambda_0^{-k H} \\bigl(\\cos(2 \\pi \\lambda_0^k t + \\phi_k) - \\cos \\phi_k\\bigr)\\,, $$\n",
    "with $(\\phi_k)_{k\\geq0} \\sim \\mathbb{U}[0, 2\\pi]$, and $\\lambda_0 > 1$ -- the fundamental harmonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEI_1.2-8388608-0.500-125x8 13237.550sec. ../results/WEI_1.2-8388608-0.500-125x8_20161021-080209.gz\n",
      "WEI_1.2-8388608-0.550-125x8 13259.886sec. ../results/WEI_1.2-8388608-0.550-125x8_20161021-114320.gz\n",
      "WEI_1.2-8388608-0.600-125x8 13295.768sec. ../results/WEI_1.2-8388608-0.600-125x8_20161021-152507.gz\n",
      "WEI_1.2-8388608-0.650-125x8"
     ]
    }
   ],
   "source": [
    "if not skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for holder_ in holder_exponents:\n",
    "        name_ = \"WEI_%g-%d-%0.3f-%dx%d\"%(lambda_0, n_samples, holder_, n_per_batch, n_batches)\n",
    "        print name_,\n",
    "\n",
    "        # Schedule the experiments\n",
    "        seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "        schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                         WeierstrassFunction(N=n_samples,\n",
    "                                                             lambda_0=lambda_0,\n",
    "                                                             holder=holder_,\n",
    "                                                             random_state=seed_,\n",
    "                                                             one_sided=False))\n",
    "                                    for seed_ in seeds)\n",
    "\n",
    "        # Run the experiment and collect the results\n",
    "        tick_ = time.time()\n",
    "        experiment_ids = list()\n",
    "        results_ = {method: list() for method in methods}\n",
    "        for id_, dict_ in par_(schedule_):\n",
    "            experiment_ids.append(id_)\n",
    "            for method in methods:\n",
    "                results_[method].extend(dict_[method])\n",
    "        results = {key_: collect_structural_statistics(list_)\n",
    "                   for key_, list_ in results_.iteritems()}\n",
    "        tock_ = time.time()\n",
    "\n",
    "        # Save the results and log\n",
    "        filename_ = save((tick_, tock_, experiment_ids, results), OUTPUT_PATH, name_)\n",
    "        print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Hermite process experiment: with downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree.processes import HermiteProcess\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, n_downsample = 1 << 19, 1 << 4\n",
    "degrees, methods = [2, 3, 4], [\"med\", \"std\", \"iqr\", \"mean\",]\n",
    "hurst_exponents = [       0.550, 0.600, 0.650, 0.700, 0.750, 0.800, 0.850, 0.900,\n",
    "                   0.910, 0.915, 0.920, 0.925, 0.930, 0.935, 0.940, 0.945, 0.950,\n",
    "                   0.990,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment for the Hermite process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for degree_ in degrees:\n",
    "        for hurst_ in hurst_exponents:\n",
    "            name_ = \"HRP%d_%d-%d-%0.3f-%dx%d\"%(degree_, n_downsample, n_samples, hurst_, n_per_batch, n_batches)\n",
    "            print name_,\n",
    "\n",
    "            # Schedule the experiments\n",
    "            seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "            schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                             HermiteProcess(N=n_samples,\n",
    "                                                            degree=degree_,\n",
    "                                                            n_downsample=n_downsample,\n",
    "                                                            hurst=hurst_,\n",
    "                                                            random_state=seed_))\n",
    "                                        for seed_ in seeds)\n",
    "\n",
    "            # Run the experiment and collect the results\n",
    "            tick_ = time.time()\n",
    "            experiment_ids = list()\n",
    "            results_ = {method: list() for method in methods}\n",
    "            for id_, dict_ in par_(schedule_):\n",
    "                experiment_ids.append(id_)\n",
    "                for method in methods:\n",
    "                    results_[method].extend(dict_[method])\n",
    "            results = {key_: collect_structural_statistics(list_)\n",
    "                       for key_, list_ in results_.iteritems()}\n",
    "            tock_ = time.time()\n",
    "\n",
    "            # Save the results and log\n",
    "            filename_ = save((tick_, tock_, experiment_ids, results), OUTPUT_PATH, name_)\n",
    "            print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weierstrass experiment -- $\\lambda_0 = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree.processes import WeierstrassFunction\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, lambda_0 = 1 << 23, 3.0\n",
    "methods = [\"med\", \"std\", \"iqr\", \"mean\",]\n",
    "holder_exponents = [0.500, 0.550, 0.600, 0.650, 0.700, 0.750, 0.800, 0.850, 0.900,\n",
    "                    0.910, 0.915, 0.920, 0.925, 0.930, 0.935, 0.940, 0.945, 0.950,\n",
    "                    0.990,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experimnet for the random Weierstrass function $[0, 1]\\mapsto \\mathbb{R}$:\n",
    "$$ W_H(t) = \\sum_{k\\geq 0} \\lambda_0^{-k H} \\bigl(\\cos(2 \\pi \\lambda_0^k t + \\phi_k) - \\cos \\phi_k\\bigr)\\,, $$\n",
    "with $(\\phi_k)_{k\\geq0} \\sim \\mathbb{U}[0, 2\\pi]$, and $\\lambda_0 > 1$ -- the fundamental harmonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for holder_ in holder_exponents:\n",
    "        name_ = \"WEI_%g-%d-%0.3f-%dx%d\"%(lambda_0, n_samples, holder_, n_per_batch, n_batches)\n",
    "        print name_,\n",
    "\n",
    "        # Schedule the experiments\n",
    "        seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "        schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                         WeierstrassFunction(N=n_samples,\n",
    "                                                             lambda_0=lambda_0,\n",
    "                                                             holder=holder_,\n",
    "                                                             random_state=seed_,\n",
    "                                                             one_sided=False))\n",
    "                                    for seed_ in seeds)\n",
    "\n",
    "        # Run the experiment and collect the results\n",
    "        tick_ = time.time()\n",
    "        experiment_ids = list()\n",
    "        results_ = {method: list() for method in methods}\n",
    "        for id_, dict_ in par_(schedule_):\n",
    "            experiment_ids.append(id_)\n",
    "            for method in methods:\n",
    "                results_[method].extend(dict_[method])\n",
    "        results = {key_: collect_structural_statistics(list_)\n",
    "                   for key_, list_ in results_.iteritems()}\n",
    "        tock_ = time.time()\n",
    "\n",
    "        # Save the results and log\n",
    "        filename_ = save((tick_, tock_, experiment_ids, results), OUTPUT_PATH, name_)\n",
    "        print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weierstrass experiment -- $\\lambda_0 = 1.7$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree.processes import WeierstrassFunction\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, lambda_0 = 1 << 23, 1.7\n",
    "methods = [\"med\", \"std\", \"iqr\", \"mean\",]\n",
    "holder_exponents = [0.500, 0.550, 0.600, 0.650, 0.700, 0.750, 0.800, 0.850, 0.900,\n",
    "                    0.910, 0.915, 0.920, 0.925, 0.930, 0.935, 0.940, 0.945, 0.950,\n",
    "                    0.990,]\n",
    "n_per_batch, n_batches = 125, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experimnet for the random Weierstrass function $[0, 1]\\mapsto \\mathbb{R}$:\n",
    "$$ W_H(t) = \\sum_{k\\geq 0} \\lambda_0^{-k H} \\bigl(\\cos(2 \\pi \\lambda_0^k t + \\phi_k) - \\cos \\phi_k\\bigr)\\,, $$\n",
    "with $(\\phi_k)_{k\\geq0} \\sim \\mathbb{U}[0, 2\\pi]$, and $\\lambda_0 > 1$ -- the fundamental harmonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for holder_ in holder_exponents:\n",
    "        name_ = \"WEI_%g-%d-%0.3f-%dx%d\"%(lambda_0, n_samples, holder_, n_per_batch, n_batches)\n",
    "        print name_,\n",
    "\n",
    "        # Schedule the experiments\n",
    "        seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "        schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                         WeierstrassFunction(N=n_samples,\n",
    "                                                             lambda_0=lambda_0,\n",
    "                                                             holder=holder_,\n",
    "                                                             random_state=seed_,\n",
    "                                                             one_sided=False))\n",
    "                                    for seed_ in seeds)\n",
    "\n",
    "        # Run the experiment and collect the results\n",
    "        tick_ = time.time()\n",
    "        experiment_ids = list()\n",
    "        results_ = {method: list() for method in methods}\n",
    "        for id_, dict_ in par_(schedule_):\n",
    "            experiment_ids.append(id_)\n",
    "            for method in methods:\n",
    "                results_[method].extend(dict_[method])\n",
    "        results = {key_: collect_structural_statistics(list_)\n",
    "                   for key_, list_ in results_.iteritems()}\n",
    "        tock_ = time.time()\n",
    "\n",
    "        # Save the results and log\n",
    "        filename_ = save((tick_, tock_, experiment_ids, results), OUTPUT_PATH, name_)\n",
    "        print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fBM experiment: super long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree.processes import FractionalBrownianMotion\n",
    "\n",
    "seed = master_seeds.pop()\n",
    "print \"Using seed %X\"%(seed,)\n",
    "random_state = np.random.RandomState(seed)\n",
    "\n",
    "skip = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples, methods = 1 << 25, [\"med\", \"std\", \"iqr\", \"mean\",]\n",
    "hurst_exponents = [0.500, 0.550, 0.600, 0.650, 0.700, 0.750, 0.800, 0.850, 0.900,\n",
    "                   0.910, 0.915, 0.920, 0.925, 0.930, 0.935, 0.940, 0.945, 0.950,\n",
    "                   0.990,]\n",
    "n_per_batch, n_batches, n_threads = 5, 2, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment for the Fractional Brownian Motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not skip:\n",
    "    par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "    for hurst_ in hurst_exponents:\n",
    "        name_ = \"FBM-%d-%0.3f-%dx%d\"%(n_samples, hurst_, n_per_batch, n_batches)\n",
    "        print name_,\n",
    "\n",
    "        # Schedule the experiments\n",
    "        seeds = random_state.randint(MAX_RAND_SEED, size=(n_batches,))\n",
    "        schedule_ = (delayed(experiment)(seed_, n_per_batch, methods,\n",
    "                                         FractionalBrownianMotion(N=n_samples,\n",
    "                                                                  hurst=hurst_,\n",
    "                                                                  random_state=seed_,\n",
    "                                                                  n_threads=n_threads))\n",
    "                                    for seed_ in seeds)\n",
    "\n",
    "        # Run the experiment and collect the results\n",
    "        tick_ = time.time()\n",
    "        experiment_ids = list()\n",
    "        results_ = {method: list() for method in methods}\n",
    "        for id_, dict_ in par_(schedule_):\n",
    "            experiment_ids.append(id_)\n",
    "            for method in methods:\n",
    "                results_[method].extend(dict_[method])\n",
    "        results = {key_: collect_structural_statistics(list_)\n",
    "                   for key_, list_ in results_.iteritems()}\n",
    "        tock_ = time.time()\n",
    "\n",
    "        # Save the results and log\n",
    "        filename_ = save((tick_, tock_, experiment_ids, results), OUTPUT_PATH, name_)\n",
    "        print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
