{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Monte Carlo Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A handy routine to store the experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time, gzip\n",
    "import os, cPickle\n",
    "\n",
    "def save(obj, path, prefix=None):\n",
    "    prefix_ = \"\" if prefix is None else \"%s_\"%(prefix,)\n",
    "    filename_ = os.path.join(path, \"%s%s.gz\"%(prefix_, time.strftime(\"%Y%m%d-%H%M%S\"),))\n",
    "    with gzip.open(filename_, \"wb+\", 9) as fout_:\n",
    "        cPickle.dump(obj, fout_)\n",
    "    return filename_\n",
    "\n",
    "def load(filename):\n",
    "    with gzip.open(filename, \"rb\") as f:\n",
    "        return cPickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crossing_tree import crossing_tree\n",
    "\n",
    "def path_analyze(X, T, scale=1.0):\n",
    "    xi, ti, offspring, Vnk, Znk, Wnk = crossing_tree(X, T, scale=scale, origin=X[0])\n",
    "    # Sanity check.\n",
    "    # for j in xrange(len(Znk)):\n",
    "    #     assert np.allclose(2 * Vnk[j][:, :2].sum(axis=1) + 2, Znk[j])\n",
    "\n",
    "    # Nn[n] -- the total number of crossings of grid with spacing \\delta 2^n\n",
    "    Nn = np.r_[len(xi), [len(index_) for index_ in offspring]] - 1\n",
    "\n",
    "    # Dnk[n][k] -- the total number of crossings of grid \\delta 2^{n+1}\n",
    "    #  with exactly 2(k+1) subcrossings of grid \\delta 2^n.\n",
    "    freq = [np.bincount(Zk)[2::2] for Zk in Znk]\n",
    "    Dnk = np.zeros((len(Znk), max(len(f) for f in freq)), np.int)\n",
    "    for l, f in enumerate(freq):\n",
    "        Dnk[l, :len(f)] = f\n",
    "\n",
    "    # Vnde[n][d][e] -- the total number of up-down(e=0) and down-up(e=1)\n",
    "    #  excursions in a downward (d=0) or upward (d=1) crossing of level\n",
    "    #  n+1\n",
    "    Vnde = np.array([(Vk[Vk[:, 2] < 0, :2].sum(axis=0),\n",
    "                      Vk[Vk[:, 2] > 0, :2].sum(axis=0))\n",
    "                     for Vk in Vnk], dtype=np.int)\n",
    "\n",
    "    # Wnp[n][p] -- the p-th empirical quantile of the n-th level crossing\n",
    "    #  durations.\n",
    "    prc = [0.1, 0.5, 1.0, 2.5, 5.0, 10, 25, 50, 75, 90, 95, 97.5, 99, 99.5, 99.9]\n",
    "    empty_ = np.full_like(prc, np.nan)\n",
    "    Wnp = np.stack([np.percentile(Wk, prc) if len(Wk) > 0 else empty_ for Wk in Wnk])\n",
    "\n",
    "    # The average crossing duration and its standard deviation\n",
    "    Wavgn = np.array([np.mean(Wk) if len(Wk) > 0 else np.nan for Wk in Wnk])\n",
    "    Wstdn = np.array([np.std(Wk) if len(Wk) > 0 else np.nan for Wk in Wnk])\n",
    "    return scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect a list of results returned by path_analyze into aligned data tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect(results):\n",
    "    results = list(results)\n",
    "\n",
    "    scale_m = np.array([scale for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results])\n",
    "\n",
    "    Nmn = [Nn for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results]\n",
    "    L = max(Nn.shape[0] for Nn in Nmn)\n",
    "    Nmn = np.stack([np.pad(Nn, (0, L - Nn.shape[0]), mode=\"constant\").astype(np.float)\n",
    "                    for Nn in Nmn])\n",
    "\n",
    "    Dmnk = [Dnk for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results]\n",
    "    K = max(Dnk.shape[1] for Dnk in Dmnk)\n",
    "    Dmnk = np.stack([np.pad(Dnk, ((0, L - 1 - Dnk.shape[0]), (0, K - Dnk.shape[1])),\n",
    "                            mode=\"constant\").astype(np.float)\n",
    "                     for Dnk in Dmnk])\n",
    "\n",
    "    Wmnp = np.stack([np.pad(Wnp.astype(np.float), ((0, L - 1 - Wnp.shape[0]), (0, 0)),\n",
    "                            mode=\"constant\", constant_values=np.nan)\n",
    "                     for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results])\n",
    "\n",
    "    Vmnde = np.stack([np.pad(Vnde.astype(np.float), ((0, L - 1 - Vnde.shape[0]),\n",
    "                                                     (0, 0), (0, 0)),\n",
    "                             mode=\"constant\", constant_values=np.nan)\n",
    "                      for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results])\n",
    "\n",
    "    Wavgmn = np.stack([np.pad(Wavgn.astype(np.float), (0, L - 1 - Wavgn.shape[0]),\n",
    "                              mode=\"constant\", constant_values=np.nan)\n",
    "                       for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results])\n",
    "\n",
    "    Wstdmn = np.stack([np.pad(Wstdn.astype(np.float), (0, L - 1 - Wstdn.shape[0]),\n",
    "                              mode=\"constant\", constant_values=np.nan)\n",
    "                       for scale, Nn, Dnk, Vnde, Wnp, Wavgn, Wstdn in results])\n",
    "\n",
    "    return scale_m, Nmn, Dmnk, Vmnde, Wmnp, Wavgmn, Wstdmn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function implementing various delta choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def get_delta_method(delta=1.0):\n",
    "    if isinstance(delta, str):\n",
    "        if delta == \"std\":\n",
    "            # the standard deviation of increments\n",
    "            delta_ = lambda X: np.diff(X).std()\n",
    "        elif delta == \"med\":\n",
    "            # Use the median absolute difference [Jones, Rolls; 2009] p. 11 (arxiv:0911.5204v2)\n",
    "            delta_ = lambda X: np.median(np.abs(np.diff(X)))\n",
    "        elif delta == \"iqr\":\n",
    "            # Interquartile range\n",
    "            delta_ = lambda X: np.subtract(*np.percentile(np.diff(X), [75, 25]))\n",
    "        elif delta == \"rng\":\n",
    "            # Use the range estimate as suggested by Geoffrey on 2015-05-28\n",
    "            warnings.warn(\"\"\"Use of `range`-based grid resolution \"\"\"\n",
    "                          \"\"\"is discouraged since it may cause misaligned \"\"\"\n",
    "                          \"\"\"crossing trees.\"\"\", RuntimeWarning)\n",
    "            delta_ = lambda X: (X.max() - X.min()) / (2**12)\n",
    "        else:\n",
    "            raise ValueError(\"\"\"Invalid `delta` setting. Accepted values \"\"\"\n",
    "                             \"\"\"are: [`iqr`, `std`, `med`, `rng`].\"\"\")\n",
    "    elif isinstance(delta, float) and delta > 0:\n",
    "        delta_ = lambda X: delta\n",
    "    else:\n",
    "        raise TypeError(\"\"\"`delta` must be either a float, or a method \"\"\"\n",
    "                        \"\"\"identifier.\"\"\")\n",
    "    return delta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An MC experiment kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def mc_run(experiment_id, n_replications, generator, method):\n",
    "    results = {method_: list() for method_ in method}\n",
    "    deltas = [get_delta_method(method_) for method_ in method]\n",
    "\n",
    "    generator = clone(generator)\n",
    "    generator.start()\n",
    "    for j in xrange(n_replications):\n",
    "        T, X = generator.draw()\n",
    "        for delta, method in zip(deltas, methods):\n",
    "            results[method].append(path_analyze(X, T, scale=delta(X)))\n",
    "    generator.finish()\n",
    "    return experiment_id, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A mock up experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the parallel backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "par_ = Parallel(n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the random states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0xDEADC0DE)\n",
    "\n",
    "# Create a bunch of random seed\n",
    "MAX_RAND_SEED = np.iinfo(np.int32).max\n",
    "seeds = random_state.randint(MAX_RAND_SEED, size=(8,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the experiment schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from crossing_tree.processes import FractionalBrownianMotion as FBM\n",
    "\n",
    "N, H, methods = (1<<15) - 1, .65, [\"med\", \"std\", \"iqr\",]\n",
    "jobs_ = (delayed(mc_run)(seed_, 125, FBM(N, hurst=H, random_state=seed_),\n",
    "                         method=methods) for seed_ in seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment and flatten the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_ids = list()\n",
    "results_ = {method: list() for method in methods}\n",
    "for id_, dict_ in par_(jobs_):\n",
    "    experiment_ids.append(id_)\n",
    "    for method in methods:\n",
    "        results_[method].extend(dict_[method])\n",
    "\n",
    "results = {key_: collect(list_) for key_, list_ in results_.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect experiment IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick one to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale_m, Nmn, Dmnk, Vmnde, Wmnp, Wavgmn, Wstdmn = results[\"std\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the number of crossings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.log(Nmn.T));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the probability distribution of the number of sub-crossings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_ = Dmnk.sum(axis=-1, keepdims=True)\n",
    "total_[total_ < 1.] = 1.0\n",
    "Dmnk /= total_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(Dmnk.mean(axis=0).T)\n",
    "ax.set_yscale(\"log\", basey=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the quantiles of the crossing durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 9))\n",
    "ax = fig.add_subplot(111)\n",
    "prc = [0.1, 0.5, 1.0, 2.5, 5.0, 10, 25, 50, 75, 90, 95, 97.5, 99, 99.5, 99.9]\n",
    "colors = plt.cm.rainbow_r(np.linspace(0, 1, num=len(Wmnp)), alpha=0.25)\n",
    "for Wnp, Nn, col_ in zip(Wmnp, Nmn, colors):\n",
    "#     wnp_ =  Wnp / 2**(np.arange(len(Nn)-1, dtype=np.float)[:, np.newaxis]/H)\n",
    "    wnp_ =  Wnp\n",
    "    for wp_ in wnp_[:-5]:\n",
    "        ax.plot(wp_, prc, color=col_)\n",
    "ax.set_xscale(\"log\", basex=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the base level resolution is distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale_m = {key_: res_[0] for key_, res_ in results.iteritems()}\n",
    "\n",
    "for key_, res_ in results.iteritems():\n",
    "    plt.hist(res_[0], bins=50, label=key_, lw=0, log=False);\n",
    "plt.legend(loc=\"best\", ncol=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The fully felged experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs the experiment for the Fractional Brownian Motion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(0xDEADC0DE)\n",
    "\n",
    "MAX_RAND_SEED = np.iinfo(np.int32).max\n",
    "seeds = random_state.randint(MAX_RAND_SEED, size=(8,))\n",
    "\n",
    "par_ = Parallel(n_jobs=-1, verbose=0)\n",
    "M, P, methods = 125, 23, [\"med\", \"std\", \"iqr\",]\n",
    "for hurst in np.linspace(.5, .95, num=10):\n",
    "    name_ = \"FBM-%d-%0.2f-%dx%d\"%(P, hurst, M, len(seeds))\n",
    "    print name_,\n",
    "\n",
    "    # Schedule the experiments\n",
    "    schedule_ = (delayed(mc_run)(seed_, 125, FBM(N=(1 << P) - 1, hurst=hurst,\n",
    "                                             random_state=seed_),\n",
    "                             method=methods) for seed_ in seeds)\n",
    "\n",
    "    # Run the experiment and collect the results\n",
    "    tick_ = time.time()\n",
    "    experiment_ids = list()\n",
    "    results_ = {method: list() for method in methods}\n",
    "    for id_, dict_ in par_(schedule_):\n",
    "        experiment_ids.append(id_)\n",
    "        for method in methods:\n",
    "            results_[method].extend(dict_[method])\n",
    "    results = {key_: collect(list_) for key_, list_ in results_.iteritems()}\n",
    "    tock_ = time.time()\n",
    "    \n",
    "    filename_ = save((tick_, tock_, experiment_ids, results), \"../results\", name_)\n",
    "\n",
    "    print \"%0.3fsec.\"%(tock_ - tick_,), filename_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
